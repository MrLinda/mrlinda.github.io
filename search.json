[{"title":"武汉大学自动评教程序","date":"2023-05-26T14:41:51.000Z","url":"/2023/05/26/WHUAutoEvaluate/","tags":[["WHU","/tags/WHU/"],["Python","/tags/Python/"]],"categories":[["小工具","/categories/%E5%B0%8F%E5%B7%A5%E5%85%B7/"]],"content":"武汉大学自动评教介绍同学们在考试过后需要在评价系统中评教后才能查询成绩，往往大多数人都厌烦这种形式主义的行为，于是我就做了这个脚本，帮助大家快速评教 详情请查看： Github 下载地址： Github 镜像"},{"title":"快速上手YOLOv5训练","date":"2023-05-21T10:37:29.000Z","url":"/2023/05/21/yolov5test/","tags":[["目标检测","/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"],["人工智能","/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"],["YOLOv5","/tags/YOLOv5/"]],"categories":[["教程","/categories/%E6%95%99%E7%A8%8B/"]],"content":"快速上手YOLOv5训练作者硬件 R7-5800H GTX1650 RAM: 16G 配置环境anaconda简介安装官网： tips：anaconda里已经包含jupyter notebook。 使用安装完成后，打开Anaconda Prompt即可使用 新建虚拟环境 激活虚拟环境 pytorch简介安装参考链接： 官网： 打开Anaconda Prompt，激活上一步新建的虚拟环境，然后输入上图中指令 PyCharm简介安装官网： 汉化 打开设置，点击File，点击Settings 点击 Plugins， 输入chinese，选中Chinese (Sinplified) Language Pack/中文语言包，点击Install 设置解释器 打开设置 在项目设置里找到python解释器 添加解释器 选择之前创建的虚拟环境 YOLOv5简介官方文档： 安装提前进到想安装的目录下后： Labelimg简介安装 使用 快捷键： 快捷键 作用 A,D 上一张图，下一张图 W 创建标签 设置路径YOLO的训练集格式： dataset #(数据集名：如kumiko)├── images #图像 ├── train #训练集 ├── xx.jpg ├── val #验证集 ├── xx.jpg├── labels #标签 ├── train #训练集 ├── xx.txt ├── val #验证集 ├── xx.txt Open Dir选择图片路径（如xxx\\datasets\\images\\train） Change Save Dir选择标签保存路径（如xxx\\datasets\\labels\\train） 设置为YOLO格式： 使用训练新建.yaml文件在yolov5\\data文件夹下新建xxx.yaml文件（如kumiko.yaml），内容如下： 下载预训练模型地址： 将模型放至yolov5文件夹下 本文以yolov5s.pt为例 新建配置 填写相关配置 名称随便填一个就好 脚本路径选择yolov5文件夹下的train.py 参数填写需要的参数，如： 详细参数可参考： 点击运行，模型即开始训练 tips: 若内存不足，可： 调大虚拟内存 调小workers 加入内存、显存回收相关代码（参考：） 参数中加入--cache disk 预测将yolov5/runs/exp/weights下的模型（best.pt）复制在yolov5文件夹下 命令行输入： 预测结果在yolov5/runs/detect下 附训练集作者自截自标注的训练集： 该模型效果： your browser does not support the video tag "},{"title":"实验四：主元分析","date":"2023-05-18T13:23:02.000Z","url":"/2023/05/18/MLExperiment4/","tags":[["实验报告","/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"]],"categories":[["课程","/categories/%E8%AF%BE%E7%A8%8B/"],["机器学习","/categories/%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"]],"content":"实验四：主元分析主元分析函数熟悉函数 输入参数： 参数 意义 n_components 整数表示保留的维度数，小数表示可解释方差占比最小值 返回值： PCA是一个类，该函数是其构造函数，因此返回的是一个对象，要使用主元分析还需要调用该类中的方法fit() 修改参数 手写数字的 PCA 噪声去除代码分析 实验结果在不同条件下，需要的主元个数： 需要的解释方差百分比 噪声 std 0.5 0.7 0.9 2 6 13 35 4 12 26 49 8 22 37 54 噪声越大，需要的主元个数越多 需要的解释方差百分比越大，需要的主元个数越多 人脸 PCA 重建 n_pcs 累计解释方差比 50 0.833 150 0.936 300 0.975 从图中可以看出，降到 100 维左右即可保留至少 90%的信息。 不同维度下人脸重建的效果： 人脸图像 PCA 前后识别率差别 主元数 识别率 未降维 0.39 30 0.50 50 0.50 100 0.41 150 0.29 使用如下代码生成 由该图像可以看出，主元数在 50 左右时，人脸重建后的识别率最高"},{"title":"实验三：模型评估与选择（2）","date":"2023-05-05T14:46:02.000Z","url":"/2023/05/05/MLExperiment3/","tags":[["实验报告","/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"]],"categories":[["课程","/categories/%E8%AF%BE%E7%A8%8B/"],["机器学习","/categories/%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"]],"content":"实验三：模型评估与选择（2）带交叉验证的最优超参数搜索函数带交叉验证的网格搜索函数熟悉函数 输入参数： 参数 意义 estimator 估计器 param_grid 需要最优化参数的取值（详情见下） scoring 模型评价标准 refit 使用在整个数据集上训练的最佳参数重新拟合估计器 cv 交叉验证的折数（默认 5 折） param_grid的形式： 列表或字典（列表中有多个字典） 列表中每项为一个字典，每个字典里键名为需要优化的参数，键值为该参数的取值列表 返回值： GridSearchCV是一个类，该函数是其构造函数，因此返回的是一个对象，要使用 GridSearch 还需要调用该类中的成员函数fit() 修改参数实验结果： scoring cv Best C Best kernel best gamma Best Train Best Test accuracy 5 1 linear 0.98021978 0.96491228 accuracy 10 100 linear 0.98468599 0.97368421 accuracy 15 0.1 linear 0.98451613 0.97368421 recall 5 1 linear 0.96470588 0.96491228 recall 10 10 rbf 0.1 0.97647059 0.92982456 recall 15 0.1 linear 0.96414141 0.97368421 precision 5 0.01 linear 1.00000000 0.95614035 precision 10 0.01 linear 1.00000000 0.95614035 precision 15 0.001 linear 1.00000000 0.94736842 f1 5 1 linear 0.97284941 0.96491228 f1 10 100 rbf 0.001 0.97859848 0.97368421 f1 15 0.1 linear 0.97802497 0.97368421 由上图可看出 10 折交叉验证比较通用。适应于大部分情况 带交叉验证的随机搜索函数熟悉函数 输入参数： 参数 意义 estimator 估计器 param_distributions 需要最优化参数的分布（使用 scipy.stats.distributions 里的分布） scoring 模型评价标准 refit 使用在整个数据集上训练的最佳参数重新拟合估计器 cv 交叉验证的折数（默认 5 折） 返回值： 类似于GridSearchCV Q: 说明为什么不能使用 ‘recall’, ‘precision’, ‘f1’，而要改为’recall_micro’, ‘precision_micro’, ‘f1_micro’，但是’accuracy’不用加‘_micro’？ A: 以’f1’为例，查阅 SKLearn 文档可知，默认是采用’binary’（二分类），而此时是三分类，默认设置无法使用；而’accuracy’是支持多分类的。 资料来源： 修改参数以scoring=&#39;precision_micro&#39;、cv=8为例，修改C的分布时，可发现其有如下几个最优解： 1.668088018810296（0~4 内） 5.595344156031953（0~6 内） 7.46045887470927（0~8 内） 实验结果： scoring cv Best C penalty Best score(train) accuracy 5 7.011113218 11 0.98 accuracy 10 7.011113218 11 0.98 accuracy 15 7.283587054 11 0.973333333 recall_micro 5 7.011113218 11 0.98 recall_micro 10 7.011113218 11 0.98 recall_micro 15 7.283587054 11 0.973333333 precision_micro 5 7.011113218 11 0.98 precision_micro 10 7.011113218 11 0.98 precision_micro 15 7.283587054 11 0.973333333 f1_micro 5 7.011113218 11 0.98 f2_micro 10 7.011113218 11 0.98 f3_micro 15 7.283587054 11 0.973333333 嵌套交叉验证的最优参数搜索方法熟悉函数 如示例代码： 嵌套交叉验证过程：示例代码中先创建GridSearchCV对象gs，再使用cross_val_score()将gs作为估计器，进行交叉验证，从而实现嵌套交叉验证。 在内部交叉验证中优化参数，在外部交叉验证中使用最优参数进行训练 修改参数运行时使用全部核（R7-5800H），实验结果如下： inner cv outer cv run time accuracy std 3 3 0.512662 0.969 0.012 3 5 0.835819 0.98 0.019 3 7 1.244654 0.982 0.025 3 10 1.860951 0.985 0.022 5 3 0.874549 0.969 0.012 5 5 1.455379 0.971 0.023 5 7 2.12064 0.978 0.024 5 10 3.27914 0.98 0.021 7 3 1.239511 0.969 0.012 7 5 2.016805 0.974 0.015 7 7 3.094155 0.974 0.028 7 10 4.624048 0.978 0.02 10 3 1.791292 0.976 0.011 10 5 2.894207 0.974 0.015 10 7 4.346896 0.98 0.024 10 10 6.557961 0.978 0.02 从表格中可以看出：准确率和标准差大致随折数增加而增大，但当折数达到一定大小后其变化很小。 其他性能评估指标混淆矩阵 输入参数： 参数 意义 y_true 目标值 y_pred 估计值 返回值：i 行 j 列的矩阵 每格表示真实标签为第 i 类、预测标签为第 j 类的样本数 ROC 曲线 ROC 面积 AUC（即 ROC 面积）越大，表示该分类器分类精度越好，AUC 大于 0.5 的分类器才有使用价值。 AUC&#x3D;1：完美分类器 AUC&#x3D;0.5：与随机分类相同 "},{"title":"实验二：模型评估与选择（1）","date":"2023-05-04T07:08:33.000Z","url":"/2023/05/04/MLExperiment2/","tags":[["实验报告","/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"]],"categories":[["课程","/categories/%E8%AF%BE%E7%A8%8B/"],["机器学习","/categories/%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"]],"content":"实验二：模型评估与选择（1）熟悉训练集-测试集划分、流水线和交叉验证函数的使用训练集-测试集划分函数 输入参数： 参数 意义 test_size 0~1 的小数：测试集占原始样本比例；整数：测试集样本数 stratify 保持划分前的分布（各类样本的占比保持不变） random_state 随机数种子 返回值： 返回值 意义 X_train 划分出的训练集数据 X_test 划分出的测试集数据 y_train 划分出的训练集标签 y_test 划分出的测试集标签 流水线函数 输入参数： 参数 意义 *steps 需要串联的估计器（estimators） **kwargs 一些关键词参数（memory，verbose） 返回值： 返回值 意义 p 返回一个 Pipeline 对象 如示例程序中： pipe_lr 为 Pipeline 类的一个实例，其步骤为： 标准化处理（StandardScaler） 主成分分析、特征降维（PCA） 逻辑回归（LogisticRegression） 交叉验证函数 输入参数： 参数 意义 estimator 估计器 X,y 训练集 cv 交叉验证的折数（默认 5 折） n_jobs 同时使用的处理器个数（默认一般为 1，-1 为全部使用） 返回值： 返回值 意义 scores 每次交叉验证的估计器的准确率 熟悉学习曲线的使用 学习曲线：在训练集和验证集上，关于训练数据规模的性能曲线。用于调试算法 熟悉函数 输入参数： 参数 意义 estimator 估计器 X,y 训练集 train_sizes 训练集的数量，用于生成学习曲线横坐标 cv 交叉验证的折数（默认 5 折） n_jobs 同时使用的处理器个数（默认一般为 1，-1 为全部使用） 返回值： 返回值 意义 train_sizes 已用于生成学习曲线的训练示例数 train_scores 训练集得分 test_scores 测试集得分 修改参数实验进行 20 次训练（train_sizes=np.linspace(0.1, 1.0, 20)） 实验结果： 训练集上，CV 越大，偏差越大，方差越小 测试集上，CV 越大，偏差越小，方差越大 因为 CV 越大，用于训练的样本越多，误差增大，因此训练准确率会下降、方差变小，而测试集样本变少，测试的方差变大。 就基础代码实际使用的数据而言，模型拟合效果不错，CV 取 5~10 时，偏差和方差都较小 熟悉验证曲线的使用验证曲线（拟合图）：反映模型泛化性能（测试误差）与模型复杂度关系的曲线，用于模型选择。 要防止过拟合，就需要进行模型选择：选择复杂度适当的模型，以达到使测试误差最小的学习目的。 熟悉函数 输入参数： 参数 意义 estimator 估计器 X,y 训练集 param_name 自变量名称 param_range 自变量 cv 交叉验证的折数（默认 5 折） 返回值： 返回值 意义 train_scores 训练集得分 test_scores 测试集得分 修改参数实验逻辑回归修改为：param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0] 实验结果： CV 取 5~10 较好 C 取 10 较好 KNN修改代码为： 第 54~60 行： 实验结果： CV 取 5~10 较好 C 取 9 较好 "},{"title":"实验一：KNN与多项式回归","date":"2023-05-03T14:58:13.000Z","url":"/2023/05/03/MLExperiment1/","tags":[["实验报告","/tags/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"]],"categories":[["课程","/categories/%E8%AF%BE%E7%A8%8B/"],["机器学习","/categories/%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"]],"content":"实验一：KNN 与多项式回归KNNwine采样率 0.3（共 42 个训练样本 11 个测试样本） 近邻范围 准确率（第一次） 准确率（第二次） 准确率（第三次） 1 81.82% 63.64% 63.64% 2 72.73% 63.64% 63.64% 3 72.73% 63.64% 63.64% 4 81.82% 63.64% 63.64% 5 81.82% 63.64% 54.55% 8 90.91% 72.73% 63.64% 10 90.91% 72.73% 54.55% 采样率 0.5（共 71 个训练样本 18 个测试样本） 近邻范围 准确率（第一次） 准确率（第二次） 准确率（第三次） 1 66.67% 72.22% 77.78% 2 66.67% 66.67% 83.33% 3 61.11% 61.11% 83.33% 4 55.56% 61.11% 72.22% 5 66.67% 61.11% 77.78% 8 72.22% 66.67% 72.22% 10 72.22% 66.67% 77.78% 采样率 0.8（共 113 个训练样本 29 个测试样本） 近邻范围 准确率（第一次） 准确率（第二次） 准确率（第三次） 1 65.52% 79.31% 51.72% 2 65.52% 65.52% 55.17% 3 62.07% 72.41% 62.07% 4 62.07% 72.41% 58.62% 5 65.52% 75.86% 58.62% 8 62.07% 72.41% 72.41% 10 62.07% 79.31% 75.86% 参数选取由以上实验可知，在 K 比较小的时方差较大，K 比较大时方差较小。因此可尽量选择较大的 K，不过 K 过大会导致过拟合，所以在该实验中 K 可选取 3~5。 优化在确定数据集合采样率后自适应选择 K 的值 运行结果： Regression信号频率 1噪声方差 0.2M&#x3D;10 M&#x3D;180 噪声方差 0.5M&#x3D;10 M&#x3D;50 M&#x3D;180 信号频率 2噪声方差 0.5M&#x3D;10 M&#x3D;180 信号频率 4噪声方差 0.2M&#x3D;10 M&#x3D;50 M&#x3D;180 噪声方差 0.5M&#x3D;30 M&#x3D;180 信号频率 8噪声方差 0.1M&#x3D;180 噪声方差 0.5M&#x3D;180 拟合效果与条件关系多项式次数越高越容易拟合高频的信号，但是多项式次数过高容易过拟合； 多项式次数越低越容易欠拟合，尤其是对于低频信号。 因此需要在尽可能拟合信号的情况下降低多项式次数，从而降低噪声对于模型训练的影响。"},{"title":"致深爱你的那个我","date":"2023-04-30T13:18:39.000Z","url":"/2023/04/30/video-test/","tags":[["test","/tags/test/"],["movie","/tags/movie/"]],"categories":[["movie","/categories/movie/"]],"content":"若未显示播放键，刷新一次就好了（正在尝试修复） player1=videojs(\"videojs1\",{language:\"zh-CN\",responsive:true,plugins:{hotkeys:{alwaysCaptureHotkeys:true},},});toast_init(player1)player1.mobileUi();videojs(document.querySelector(\"video\")).remember({\"localStorageKey\": \"videojs.remember.myvideo\"});"}]